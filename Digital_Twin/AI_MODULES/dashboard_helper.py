#!/usr/bin/env python3
"""
Dashboard Helper Module for Digital Twin System
Provides data processing, aggregation, and formatting for dashboard visualization.
"""

import numpy as np
import pandas as pd
import logging
import json
import sqlite3
import pickle
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
from collections import defaultdict, deque
import warnings
warnings.filterwarnings('ignore')

# Statistical and ML imports
from scipy import stats
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Time series analysis
import statsmodels.api as sm
from statsmodels.tsa.seasonal import seasonal_decompose

class DashboardHelper:
    """
    Comprehensive dashboard helper for Digital Twin applications.
    Provides data processing, aggregation, chart preparation, and real-time updates.
    """
    
    def __init__(self, cache_path: str = "ANALYTICS/analysis_cache/"):
        self.cache_path = Path(cache_path)
        self.logger = self._setup_logging()
        
        # Create cache directory
        self.cache_path.mkdir(parents=True, exist_ok=True)
        
        # Data caches
        self.data_cache = {}
        self.cache_timestamps = {}
        self.cache_ttl = 300  # 5 minutes
        
        # Aggregation settings
        self.aggregation_config = {
            'temperature': {'unit': '째C', 'normal_range': (15, 35), 'precision': 1},
            'pressure': {'unit': 'hPa', 'normal_range': (950, 1050), 'precision': 1},
            'vibration': {'unit': 'mm/s', 'normal_range': (0, 0.5), 'precision': 3},
            'humidity': {'unit': '%RH', 'normal_range': (30, 70), 'precision': 1},
            'power': {'unit': 'W', 'normal_range': (800, 2000), 'precision': 1},
            'efficiency': {'unit': '%', 'normal_range': (70, 100), 'precision': 1}
        }
        
        # Chart color schemes
        self.color_schemes = {
            'primary': ['#3498db', '#2ecc71', '#f39c12', '#e74c3c', '#9b59b6'],
            'status': {
                'normal': '#27ae60',
                'warning': '#f39c12', 
                'critical': '#e74c3c',
                'offline': '#95a5a6'
            },
            'health': {
                'excellent': '#27ae60',
                'good': '#2ecc71',
                'fair': '#f39c12',
                'poor': '#e67e22',
                'critical': '#e74c3c'
            }
        }
        
        # Real-time data buffer
        self.realtime_buffer = defaultdict(lambda: deque(maxlen=100))
        
    def _setup_logging(self):
        """Setup logging for dashboard helper."""
        logger = logging.getLogger('DashboardHelper')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            # Ensure logs directory exists
            Path("LOGS").mkdir(exist_ok=True)
            handler = logging.FileHandler('LOGS/digital_twin_dashboard.log')
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def get_dashboard_overview(self, device_data: List[Dict] = None) -> Dict:
        """
        Get comprehensive dashboard overview data.
        
        Args:
            device_data: Optional device data, will fetch if not provided
            
        Returns:
            Dictionary containing dashboard overview metrics
        """
        try:
            self.logger.info("Generating dashboard overview")
            
            if device_data is None:
                device_data = self._fetch_device_data()
            
            if not device_data:
                return self._get_default_overview()
            
            # Convert to DataFrame for easier processing
            df = pd.DataFrame(device_data)
            
            # Calculate key metrics
            overview = {
                'timestamp': datetime.now().isoformat(),
                'system_metrics': self._calculate_system_metrics(df),
                'device_metrics': self._calculate_device_metrics(df),
                'health_metrics': self._calculate_health_metrics(df),
                'performance_metrics': self._calculate_performance_metrics(df),
                'status_distribution': self._calculate_status_distribution(df),
                'trend_analysis': self._calculate_trend_analysis(df),
                'alerts_summary': self._get_alerts_summary(),
                'energy_metrics': self._calculate_energy_metrics(df)
            }
            
            return overview
            
        except Exception as e:
            self.logger.error(f"Dashboard overview generation error: {e}")
            return self._get_default_overview()
    
    def _fetch_device_data(self) -> List[Dict]:
        """Fetch latest device data from database."""
        try:
            db_path = "DATABASE/health_data.db"
            
            if not Path(db_path).exists():
                return self._generate_sample_device_data()
            
            with sqlite3.connect(db_path) as conn:
                query = """
                    SELECT device_id, device_name, device_type, value, unit, status, 
                           health_score, efficiency_score, location, timestamp,
                           operating_hours, days_since_maintenance
                    FROM device_data 
                    WHERE timestamp >= datetime('now', '-1 day')
                    ORDER BY timestamp DESC
                """
                
                df = pd.read_sql_query(query, conn)
                return df.to_dict('records')
                
        except Exception as e:
            self.logger.error(f"Error fetching device data: {e}")
            return self._generate_sample_device_data()
    
    def _generate_sample_device_data(self) -> List[Dict]:
        """Generate sample device data for demonstration."""
        try:
            devices = []
            device_types = ['temperature_sensor', 'pressure_sensor', 'vibration_sensor', 
                          'humidity_sensor', 'power_meter']
            locations = ['Factory Floor A', 'Factory Floor B', 'Warehouse', 'Quality Lab']
            
            for i in range(20):
                device_type = np.random.choice(device_types)
                
                # Generate realistic values based on device type
                if device_type == 'temperature_sensor':
                    value = np.random.uniform(18, 35)
                    unit = '째C'
                elif device_type == 'pressure_sensor':
                    value = np.random.uniform(900, 1100)
                    unit = 'hPa'
                elif device_type == 'vibration_sensor':
                    value = np.random.uniform(0.1, 0.6)
                    unit = 'mm/s'
                elif device_type == 'humidity_sensor':
                    value = np.random.uniform(30, 80)
                    unit = '%RH'
                else:  # power_meter
                    value = np.random.uniform(800, 2000)
                    unit = 'W'
                
                # Determine status based on value ranges
                config = self.aggregation_config.get(device_type.split('_')[0], {})
                normal_range = config.get('normal_range', (0, 100))
                
                if normal_range[0] <= value <= normal_range[1]:
                    status = 'normal'
                    health_score = np.random.uniform(0.8, 1.0)
                elif value < normal_range[0] * 0.8 or value > normal_range[1] * 1.2:
                    status = 'critical'
                    health_score = np.random.uniform(0.2, 0.5)
                else:
                    status = 'warning'
                    health_score = np.random.uniform(0.5, 0.8)
                
                devices.append({
                    'device_id': f'DEVICE_{i+1:03d}',
                    'device_name': f'{device_type.replace("_", " ").title()} {i+1:03d}',
                    'device_type': device_type,
                    'value': round(value, config.get('precision', 1)),
                    'unit': unit,
                    'status': status,
                    'health_score': health_score,
                    'efficiency_score': np.random.uniform(0.7, 1.0),
                    'location': np.random.choice(locations),
                    'timestamp': datetime.now().isoformat(),
                    'operating_hours': np.random.uniform(100, 8000),
                    'days_since_maintenance': np.random.randint(1, 90)
                })
            
            return devices
            
        except Exception as e:
            self.logger.error(f"Sample data generation error: {e}")
            return []
    
    def _calculate_system_metrics(self, df: pd.DataFrame) -> Dict:
        """Calculate system-level metrics."""
        try:
            total_devices = len(df['device_id'].unique()) if 'device_id' in df.columns else 0
            
            if total_devices == 0:
                return {'total_devices': 0, 'active_devices': 0, 'uptime': 100.0}
            
            # Get latest data for each device
            latest_df = df.groupby('device_id').last().reset_index()
            
            active_devices = len(latest_df[latest_df['status'] == 'normal']) if 'status' in latest_df.columns else 0
            
            # Calculate system uptime based on device status
            uptime = (active_devices / total_devices) * 100 if total_devices > 0 else 100.0
            
            # Calculate average response time (simulated)
            response_time = np.random.uniform(50, 200)
            
            return {
                'total_devices': total_devices,
                'active_devices': active_devices,
                'offline_devices': total_devices - active_devices,
                'uptime': round(uptime, 2),
                'response_time_ms': round(response_time, 1),
                'data_points_collected': len(df),
                'last_update': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"System metrics calculation error: {e}")
            return {'total_devices': 0, 'active_devices': 0, 'uptime': 0.0}
    
    def _calculate_device_metrics(self, df: pd.DataFrame) -> Dict:
        """Calculate device-specific metrics."""
        try:
            if df.empty:
                return {}
            
            # Get latest data for each device
            latest_df = df.groupby('device_id').last().reset_index()
            
            device_metrics = {}
            
            for device_type in latest_df['device_type'].unique():
                type_df = latest_df[latest_df['device_type'] == device_type]
                
                device_metrics[device_type] = {
                    'count': len(type_df),
                    'average_value': round(type_df['value'].mean(), 2) if 'value' in type_df.columns else 0,
                    'min_value': round(type_df['value'].min(), 2) if 'value' in type_df.columns else 0,
                    'max_value': round(type_df['value'].max(), 2) if 'value' in type_df.columns else 0,
                    'unit': type_df['unit'].iloc[0] if 'unit' in type_df.columns else 'units',
                    'status_distribution': type_df['status'].value_counts().to_dict() if 'status' in type_df.columns else {}
                }
            
            return device_metrics
            
        except Exception as e:
            self.logger.error(f"Device metrics calculation error: {e}")
            return {}
    
    def _calculate_health_metrics(self, df: pd.DataFrame) -> Dict:
        """Calculate health-related metrics."""
        try:
            if df.empty or 'health_score' not in df.columns:
                return self._get_default_health_metrics()
            
            # Get latest health scores for each device
            latest_df = df.groupby('device_id').last().reset_index()
            health_scores = latest_df['health_score'].dropna()
            
            if health_scores.empty:
                return self._get_default_health_metrics()
            
            # Convert to percentages
            health_scores_pct = health_scores * 100
            
            # Calculate health distribution
            health_distribution = {
                'excellent': len(health_scores[health_scores >= 0.9]),
                'good': len(health_scores[(health_scores >= 0.7) & (health_scores < 0.9)]),
                'fair': len(health_scores[(health_scores >= 0.5) & (health_scores < 0.7)]),
                'poor': len(health_scores[(health_scores >= 0.3) & (health_scores < 0.5)]),
                'critical': len(health_scores[health_scores < 0.3])
            }
            
            # Calculate trend (simplified)
            health_trend = self._calculate_health_trend(df)
            
            return {
                'average_health': round(health_scores_pct.mean(), 1),
                'median_health': round(health_scores_pct.median(), 1),
                'min_health': round(health_scores_pct.min(), 1),
                'max_health': round(health_scores_pct.max(), 1),
                'std_health': round(health_scores_pct.std(), 1),
                'health_distribution': health_distribution,
                'health_trend': health_trend,
                'devices_needing_attention': health_distribution['poor'] + health_distribution['critical']
            }
            
        except Exception as e:
            self.logger.error(f"Health metrics calculation error: {e}")
            return self._get_default_health_metrics()
    
    def _calculate_health_trend(self, df: pd.DataFrame) -> str:
        """Calculate health trend direction."""
        try:
            if len(df) < 10:
                return 'stable'
            
            # Sort by timestamp and calculate moving average
            df_sorted = df.sort_values('timestamp')
            recent_health = df_sorted['health_score'].tail(10).mean()
            older_health = df_sorted['health_score'].head(10).mean()
            
            diff = recent_health - older_health
            
            if diff > 0.05:
                return 'improving'
            elif diff < -0.05:
                return 'declining'
            else:
                return 'stable'
                
        except Exception as e:
            self.logger.error(f"Health trend calculation error: {e}")
            return 'stable'
    
    def _get_default_health_metrics(self) -> Dict:
        """Get default health metrics when no data is available."""
        return {
            'average_health': 85.0,
            'median_health': 87.0,
            'min_health': 65.0,
            'max_health': 98.0,
            'std_health': 12.5,
            'health_distribution': {
                'excellent': 5, 'good': 8, 'fair': 4, 'poor': 2, 'critical': 1
            },
            'health_trend': 'stable',
            'devices_needing_attention': 3
        }
    
    def _calculate_performance_metrics(self, df: pd.DataFrame) -> Dict:
        """Calculate performance-related metrics."""
        try:
            if df.empty or 'efficiency_score' not in df.columns:
                return self._get_default_performance_metrics()
            
            # Get latest efficiency scores for each device
            latest_df = df.groupby('device_id').last().reset_index()
            efficiency_scores = latest_df['efficiency_score'].dropna() * 100
            
            # Calculate operating hours statistics
            operating_hours_stats = {}
            if 'operating_hours' in latest_df.columns:
                operating_hours = latest_df['operating_hours'].dropna()
                operating_hours_stats = {
                    'total_operating_hours': round(operating_hours.sum(), 0),
                    'average_operating_hours': round(operating_hours.mean(), 0),
                    'max_operating_hours': round(operating_hours.max(), 0)
                }
            
            # Calculate maintenance statistics
            maintenance_stats = {}
            if 'days_since_maintenance' in latest_df.columns:
                maintenance_days = latest_df['days_since_maintenance'].dropna()
                maintenance_stats = {
                    'average_days_since_maintenance': round(maintenance_days.mean(), 0),
                    'devices_due_maintenance': len(maintenance_days[maintenance_days > 60]),
                    'devices_overdue_maintenance': len(maintenance_days[maintenance_days > 90])
                }
            
            return {
                'average_efficiency': round(efficiency_scores.mean(), 1) if not efficiency_scores.empty else 85.0,
                'min_efficiency': round(efficiency_scores.min(), 1) if not efficiency_scores.empty else 70.0,
                'max_efficiency': round(efficiency_scores.max(), 1) if not efficiency_scores.empty else 98.0,
                'efficiency_trend': self._calculate_efficiency_trend(df),
                **operating_hours_stats,
                **maintenance_stats
            }
            
        except Exception as e:
            self.logger.error(f"Performance metrics calculation error: {e}")
            return self._get_default_performance_metrics()
    
    def _calculate_efficiency_trend(self, df: pd.DataFrame) -> str:
        """Calculate efficiency trend direction."""
        try:
            if len(df) < 10 or 'efficiency_score' not in df.columns:
                return 'stable'
            
            df_sorted = df.sort_values('timestamp')
            recent_efficiency = df_sorted['efficiency_score'].tail(10).mean()
            older_efficiency = df_sorted['efficiency_score'].head(10).mean()
            
            diff = recent_efficiency - older_efficiency
            
            if diff > 0.05:
                return 'improving'
            elif diff < -0.05:
                return 'declining'
            else:
                return 'stable'
                
        except Exception as e:
            return 'stable'
    
    def _get_default_performance_metrics(self) -> Dict:
        """Get default performance metrics when no data is available."""
        return {
            'average_efficiency': 85.5,
            'min_efficiency': 68.0,
            'max_efficiency': 97.5,
            'efficiency_trend': 'stable',
            'total_operating_hours': 45000,
            'average_operating_hours': 2250,
            'max_operating_hours': 8760,
            'average_days_since_maintenance': 32,
            'devices_due_maintenance': 3,
            'devices_overdue_maintenance': 1
        }
    
    def _calculate_status_distribution(self, df: pd.DataFrame) -> Dict:
        """Calculate device status distribution."""
        try:
            if df.empty or 'status' not in df.columns:
                return {'normal': 15, 'warning': 3, 'critical': 2}
            
            # Get latest status for each device
            latest_df = df.groupby('device_id').last().reset_index()
            status_counts = latest_df['status'].value_counts().to_dict()
            
            # Ensure all status types are present
            status_distribution = {
                'normal': status_counts.get('normal', 0),
                'warning': status_counts.get('warning', 0),
                'critical': status_counts.get('critical', 0),
                'offline': status_counts.get('offline', 0)
            }
            
            return status_distribution
            
        except Exception as e:
            self.logger.error(f"Status distribution calculation error: {e}")
            return {'normal': 15, 'warning': 3, 'critical': 2}
    
    def _calculate_trend_analysis(self, df: pd.DataFrame) -> Dict:
        """Calculate trend analysis for key metrics."""
        try:
            trends = {}
            
            # Analyze trends for different metrics
            if not df.empty:
                # Health trend
                trends['health'] = self._calculate_health_trend(df)
                
                # Efficiency trend
                trends['efficiency'] = self._calculate_efficiency_trend(df)
                
                # Device count trend (simplified)
                trends['device_count'] = 'stable'
                
                # Alert trend (simplified)
                trends['alerts'] = 'decreasing'
            else:
                trends = {
                    'health': 'stable',
                    'efficiency': 'stable',
                    'device_count': 'stable',
                    'alerts': 'stable'
                }
            
            return trends
            
        except Exception as e:
            self.logger.error(f"Trend analysis calculation error: {e}")
            return {'health': 'stable', 'efficiency': 'stable'}
    
    def _get_alerts_summary(self) -> Dict:
        """Get alerts summary information."""
        try:
            # In a real implementation, this would fetch from the alert system
            # For now, return simulated data
            return {
                'total_alerts': 8,
                'critical_alerts': 1,
                'warning_alerts': 4,
                'info_alerts': 3,
                'recent_alerts': [
                    {
                        'id': 'alert_001',
                        'title': 'Temperature High',
                        'severity': 'warning',
                        'device_id': 'DEVICE_003',
                        'timestamp': (datetime.now() - timedelta(minutes=15)).isoformat()
                    },
                    {
                        'id': 'alert_002',
                        'title': 'Pressure Critical',
                        'severity': 'critical',
                        'device_id': 'DEVICE_007',
                        'timestamp': (datetime.now() - timedelta(minutes=5)).isoformat()
                    }
                ]
            }
            
        except Exception as e:
            self.logger.error(f"Alerts summary error: {e}")
            return {'total_alerts': 0, 'critical_alerts': 0}
    
    def _calculate_energy_metrics(self, df: pd.DataFrame) -> Dict:
        """Calculate energy consumption metrics."""
        try:
            # Try to get energy data from database
            energy_data = self._fetch_energy_data()
            
            if energy_data:
                current_power = energy_data.get('current_power', 1250)
                daily_energy = energy_data.get('daily_energy', 28.5)
                monthly_cost = energy_data.get('monthly_cost', 450)
            else:
                # Generate realistic simulated data
                hour = datetime.now().hour
                base_power = 1200
                load_factor = 0.8 + 0.3 * np.sin(2 * np.pi * hour / 24)
                current_power = base_power * load_factor
                daily_energy = current_power * 24 / 1000  # kWh
                monthly_cost = daily_energy * 30 * 0.12  # $0.12 per kWh
            
            return {
                'current_power_kw': round(current_power, 1),
                'daily_energy_kwh': round(daily_energy, 1),
                'monthly_cost_usd': round(monthly_cost, 0),
                'energy_efficiency': round(np.random.uniform(85, 95), 1),
                'carbon_footprint_kg': round(daily_energy * 0.4, 1)  # 0.4 kg CO2 per kWh
            }
            
        except Exception as e:
            self.logger.error(f"Energy metrics calculation error: {e}")
            return {
                'current_power_kw': 1250.0,
                'daily_energy_kwh': 30.0,
                'monthly_cost_usd': 432.0,
                'energy_efficiency': 88.5,
                'carbon_footprint_kg': 12.0
            }
    
    def _fetch_energy_data(self) -> Dict:
        """Fetch energy data from database."""
        try:
            db_path = "DATABASE/health_data.db"
            
            if not Path(db_path).exists():
                return {}
            
            with sqlite3.connect(db_path) as conn:
                query = """
                    SELECT power_consumption_kw, energy_consumed_kwh, cost_usd
                    FROM energy_data 
                    ORDER BY timestamp DESC 
                    LIMIT 1
                """
                
                df = pd.read_sql_query(query, conn)
                
                if not df.empty:
                    return {
                        'current_power': df.iloc[0]['power_consumption_kw'],
                        'daily_energy': df.iloc[0]['energy_consumed_kwh'],
                        'monthly_cost': df.iloc[0]['cost_usd']
                    }
            
            return {}
            
        except Exception as e:
            self.logger.error(f"Energy data fetch error: {e}")
            return {}
    
    def _get_default_overview(self) -> Dict:
        """Get default dashboard overview when no data is available."""
        return {
            'timestamp': datetime.now().isoformat(),
            'system_metrics': {'total_devices': 0, 'active_devices': 0, 'uptime': 0.0},
            'device_metrics': {},
            'health_metrics': self._get_default_health_metrics(),
            'performance_metrics': self._get_default_performance_metrics(),
            'status_distribution': {'normal': 0, 'warning': 0, 'critical': 0},
            'trend_analysis': {'health': 'stable', 'efficiency': 'stable'},
            'alerts_summary': {'total_alerts': 0, 'critical_alerts': 0},
            'energy_metrics': {
                'current_power_kw': 0.0,
                'daily_energy_kwh': 0.0,
                'monthly_cost_usd': 0.0,
                'energy_efficiency': 0.0
            }
        }
    
    def prepare_chart_data(self, chart_type: str, data_source: str = 'database', 
                          time_range: str = '24h', device_id: str = None) -> Dict:
        """
        Prepare data for specific chart types.
        
        Args:
            chart_type: Type of chart ('line', 'bar', 'pie', 'gauge', 'heatmap')
            data_source: Data source ('database', 'realtime', 'sample')
            time_range: Time range for data ('1h', '24h', '7d', '30d')
            device_id: Optional specific device ID
            
        Returns:
            Chart-ready data structure
        """
        try:
            self.logger.info(f"Preparing {chart_type} chart data for {time_range}")
            
            if chart_type == 'line':
                return self._prepare_line_chart_data(time_range, device_id)
            elif chart_type == 'bar':
                return self._prepare_bar_chart_data(time_range, device_id)
            elif chart_type == 'pie':
                return self._prepare_pie_chart_data()
            elif chart_type == 'gauge':
                return self._prepare_gauge_chart_data(device_id)
            elif chart_type == 'heatmap':
                return self._prepare_heatmap_data(time_range)
            else:
                return {'error': f'Unsupported chart type: {chart_type}'}
                
        except Exception as e:
            self.logger.error(f"Chart data preparation error: {e}")
            return {'error': str(e)}
    
    def _prepare_line_chart_data(self, time_range: str, device_id: str = None) -> Dict:
        """Prepare data for line charts (time series)."""
        try:
            # Calculate number of data points based on time range
            time_ranges = {
                '1h': (1, 60),    # 1 hour, 60 minutes
                '24h': (24, 60),  # 24 hours, every hour  
                '7d': (7, 24),    # 7 days, daily points
                '30d': (30, 24)   # 30 days, daily points
            }
            
            duration, frequency = time_ranges.get(time_range, (24, 60))
            
            # Generate timestamps
            now = datetime.now()
            if time_range == '1h':
                timestamps = [now - timedelta(minutes=i) for i in range(frequency-1, -1, -1)]
                labels = [ts.strftime('%H:%M') for ts in timestamps]
            elif time_range == '24h':
                timestamps = [now - timedelta(hours=i) for i in range(duration-1, -1, -1)]
                labels = [ts.strftime('%H:%M') for ts in timestamps]
            else:
                timestamps = [now - timedelta(days=i) for i in range(duration-1, -1, -1)]
                labels = [ts.strftime('%m/%d') for ts in timestamps]
            
            # Generate realistic data patterns
            datasets = []
            
            if device_id:
                # Single device data
                datasets.append({
                    'label': f'Device {device_id}',
                    'data': self._generate_time_series_pattern(duration, 'temperature'),
                    'borderColor': self.color_schemes['primary'][0],
                    'backgroundColor': self.color_schemes['primary'][0] + '20',
                    'unit': '째C'
                })
            else:
                # Multiple metrics
                metrics = [
                    ('Temperature', 'temperature', '째C'),
                    ('Pressure', 'pressure', 'hPa'),
                    ('Vibration', 'vibration', 'mm/s'),
                    ('Efficiency', 'efficiency', '%')
                ]
                
                for i, (label, metric_type, unit) in enumerate(metrics):
                    datasets.append({
                        'label': label,
                        'data': self._generate_time_series_pattern(len(labels), metric_type),
                        'borderColor': self.color_schemes['primary'][i % len(self.color_schemes['primary'])],
                        'backgroundColor': self.color_schemes['primary'][i % len(self.color_schemes['primary'])] + '20',
                        'unit': unit
                    })
            
            return {
                'type': 'line',
                'labels': labels,
                'datasets': datasets,
                'options': {
                    'responsive': True,
                    'scales': {
                        'x': {'display': True, 'title': {'display': True, 'text': 'Time'}},
                        'y': {'display': True, 'title': {'display': True, 'text': 'Value'}}
                    },
                    'plugins': {
                        'legend': {'display': True},
                        'tooltip': {'mode': 'index', 'intersect': False}
                    }
                }
            }
            
        except Exception as e:
            self.logger.error(f"Line chart data preparation error: {e}")
            return {'error': str(e)}
    
    def _prepare_bar_chart_data(self, time_range: str, device_id: str = None) -> Dict:
        """Prepare data for bar charts."""
        try:
            if device_id:
                # Single device metrics
                labels = ['Health Score', 'Efficiency', 'Uptime', 'Performance']
                data = [
                    np.random.uniform(70, 95),
                    np.random.uniform(75, 90),
                    np.random.uniform(95, 99),
                    np.random.uniform(80, 95)
                ]
                colors = [self.color_schemes['health']['good']] * len(labels)
            else:
                # Device type comparison
                device_types = ['Temperature', 'Pressure', 'Vibration', 'Humidity', 'Power']
                labels = device_types
                data = [np.random.randint(2, 8) for _ in device_types]
                colors = self.color_schemes['primary'][:len(labels)]
            
            return {
                'type': 'bar',
                'labels': labels,
                'datasets': [{
                    'label': 'Device Count' if not device_id else 'Metrics',
                    'data': data,
                    'backgroundColor': colors,
                    'borderColor': [color.replace('20', '') for color in colors] if isinstance(colors[0], str) else colors,
                    'borderWidth': 1
                }],
                'options': {
                    'responsive': True,
                    'scales': {
                        'y': {'beginAtZero': True}
                    },
                    'plugins': {
                        'legend': {'display': False}
                    }
                }
            }
            
        except Exception as e:
            self.logger.error(f"Bar chart data preparation error: {e}")
            return {'error': str(e)}
    
    def _prepare_pie_chart_data(self) -> Dict:
        """Prepare data for pie charts (status distribution)."""
        try:
            # Get device status distribution
            device_data = self._fetch_device_data()
            df = pd.DataFrame(device_data)
            
            if not df.empty and 'status' in df.columns:
                status_counts = df.groupby('device_id')['status'].last().value_counts()
                labels = list(status_counts.index)
                data = list(status_counts.values)
            else:
                # Default data
                labels = ['Normal', 'Warning', 'Critical']
                data = [15, 3, 2]
            
            # Map colors
            colors = [self.color_schemes['status'].get(label.lower(), '#95a5a6') for label in labels]
            
            return {
                'type': 'pie',
                'labels': labels,
                'datasets': [{
                    'data': data,
                    'backgroundColor': colors,
                    'borderWidth': 2,
                    'borderColor': '#ffffff'
                }],
                'options': {
                    'responsive': True,
                    'plugins': {
                        'legend': {'position': 'bottom'},
                        'tooltip': {
                            'callbacks': {
                                'label': 'function(context) { return context.label + \': \' + context.parsed + \' devices\'; }'
                            }
                        }
                    }
                }
            }
            
        except Exception as e:
            self.logger.error(f"Pie chart data preparation error: {e}")
            return {'error': str(e)}
    
    def _prepare_gauge_chart_data(self, device_id: str = None) -> Dict:
        """Prepare data for gauge charts."""
        try:
            if device_id:
                # Single device health gauge
                device_data = self._fetch_device_data()
                device = next((d for d in device_data if d.get('device_id') == device_id), None)
                
                if device and 'health_score' in device:
                    value = device['health_score'] * 100
                else:
                    value = np.random.uniform(70, 95)
            else:
                # System health gauge
                overview = self.get_dashboard_overview()
                value = overview.get('health_metrics', {}).get('average_health', 85)
            
            # Determine color based on value
            if value >= 90:
                color = self.color_schemes['health']['excellent']
            elif value >= 75:
                color = self.color_schemes['health']['good']
            elif value >= 60:
                color = self.color_schemes['health']['fair']
            elif value >= 40:
                color = self.color_schemes['health']['poor']
            else:
                color = self.color_schemes['health']['critical']
            
            return {
                'type': 'gauge',
                'value': round(value, 1),
                'min': 0,
                'max': 100,
                'color': color,
                'title': f'Health Score' + (f' - {device_id}' if device_id else ''),
                'unit': '%',
                'thresholds': [
                    {'value': 40, 'color': self.color_schemes['health']['critical']},
                    {'value': 60, 'color': self.color_schemes['health']['poor']},
                    {'value': 75, 'color': self.color_schemes['health']['fair']},
                    {'value': 90, 'color': self.color_schemes['health']['good']},
                    {'value': 100, 'color': self.color_schemes['health']['excellent']}
                ]
            }
            
        except Exception as e:
            self.logger.error(f"Gauge chart data preparation error: {e}")
            return {'error': str(e)}
    
    def _prepare_heatmap_data(self, time_range: str) -> Dict:
        """Prepare data for heatmap visualization."""
        try:
            # Generate device location heatmap data
            device_data = self._fetch_device_data()
            locations = ['Factory Floor A', 'Factory Floor B', 'Warehouse', 'Quality Lab']
            device_types = ['temperature_sensor', 'pressure_sensor', 'vibration_sensor', 'humidity_sensor']
            
            # Create matrix data
            matrix_data = []
            for i, location in enumerate(locations):
                row = []
                for j, device_type in enumerate(device_types):
                    # Count devices of this type in this location
                    count = len([d for d in device_data 
                               if d.get('location') == location and d.get('device_type') == device_type])
                    row.append(count)
                matrix_data.append(row)
            
            return {
                'type': 'heatmap',
                'data': matrix_data,
                'xLabels': [dt.replace('_sensor', '').title() for dt in device_types],
                'yLabels': locations,
                'colorScale': {
                    'min': 0,
                    'max': max(max(row) for row in matrix_data) if matrix_data else 5,
                    'colors': ['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', '#3182bd', '#08519c']
                },
                'options': {
                    'responsive': True,
                    'plugins': {
                        'tooltip': {
                            'callbacks': {
                                'title': 'function(context) { return context[0].dataset.yLabels[context[0].dataIndex]; }',
                                'label': 'function(context) { return context.dataset.xLabels[context.dataIndex] + \': \' + context.raw + \' devices\'; }'
                            }
                        }
                    }
                }
            }
            
        except Exception as e:
            self.logger.error(f"Heatmap data preparation error: {e}")
            return {'error': str(e)}
    
    def _generate_time_series_pattern(self, length: int, metric_type: str) -> List[float]:
        """Generate realistic time series pattern for a metric type."""
        try:
            patterns = {
                'temperature': {'base': 25, 'amplitude': 5, 'frequency': 0.1, 'noise': 1},
                'pressure': {'base': 1013, 'amplitude': 20, 'frequency': 0.05, 'noise': 5},
                'vibration': {'base': 0.25, 'amplitude': 0.1, 'frequency': 0.15, 'noise': 0.05},
                'humidity': {'base': 55, 'amplitude': 15, 'frequency': 0.08, 'noise': 3},
                'power': {'base': 1200, 'amplitude': 300, 'frequency': 0.06, 'noise': 50},
                'efficiency': {'base': 85, 'amplitude': 10, 'frequency': 0.04, 'noise': 2}
            }
            
            config = patterns.get(metric_type, patterns['temperature'])
            
            data = []
            for i in range(length):
                # Base pattern with sine wave
                value = config['base'] + config['amplitude'] * np.sin(i * config['frequency'])
                
                # Add noise
                value += np.random.normal(0, config['noise'])
                
                # Ensure positive values for certain metrics
                if metric_type in ['vibration', 'power', 'efficiency']:
                    value = max(value, 0)
                
                data.append(round(value, 2))
            
            return data
            
        except Exception as e:
            self.logger.error(f"Time series pattern generation error: {e}")
            return [0] * length
    
    def get_realtime_updates(self, client_id: str = None) -> Dict:
        """
        Get real-time updates for dashboard.
        
        Args:
            client_id: Optional client identifier for personalized updates
            
        Returns:
            Real-time update data
        """
        try:
            # Get fresh data
            device_data = self._fetch_device_data()
            df = pd.DataFrame(device_data)
            
            # Calculate deltas from previous values
            updates = {
                'timestamp': datetime.now().isoformat(),
                'metrics': {
                    'system_health': self._get_metric_with_delta('system_health', df),
                    'active_devices': self._get_metric_with_delta('active_devices', df),
                    'energy_usage': self._get_metric_with_delta('energy_usage', df),
                    'efficiency': self._get_metric_with_delta('efficiency', df)
                },
                'alerts': self._get_new_alerts(),
                'device_updates': self._get_device_updates(df),
                'status_changes': self._get_status_changes(df)
            }
            
            # Store current values for next delta calculation
            self._store_previous_values(updates['metrics'])
            
            return updates
            
        except Exception as e:
            self.logger.error(f"Real-time updates error: {e}")
            return {'timestamp': datetime.now().isoformat(), 'error': str(e)}
    
    def _get_metric_with_delta(self, metric_name: str, df: pd.DataFrame) -> Dict:
        """Get metric value with delta from previous reading."""
        try:
            # Calculate current value based on metric type
            if metric_name == 'system_health':
                if not df.empty and 'health_score' in df.columns:
                    current_value = df.groupby('device_id')['health_score'].last().mean() * 100
                else:
                    current_value = 85.0
            elif metric_name == 'active_devices':
                if not df.empty and 'status' in df.columns:
                    current_value = len(df[df.groupby('device_id')['status'].last() == 'normal'])
                else:
                    current_value = 15
            elif metric_name == 'energy_usage':
                energy_data = self._fetch_energy_data()
                current_value = energy_data.get('current_power', 1250.0)
            elif metric_name == 'efficiency':
                if not df.empty and 'efficiency_score' in df.columns:
                    current_value = df.groupby('device_id')['efficiency_score'].last().mean() * 100
                else:
                    current_value = 85.5
            else:
                current_value = 0
            
            # Get previous value
            previous_value = getattr(self, f'_prev_{metric_name}', current_value)
            
            # Calculate delta
            delta = current_value - previous_value
            delta_percent = (delta / previous_value * 100) if previous_value != 0 else 0
            
            return {
                'value': round(current_value, 1),
                'delta': round(delta, 1),
                'delta_percent': round(delta_percent, 1),
                'trend': 'up' if delta > 0.1 else 'down' if delta < -0.1 else 'stable'
            }
            
        except Exception as e:
            self.logger.error(f"Metric delta calculation error for {metric_name}: {e}")
            return {'value': 0, 'delta': 0, 'delta_percent': 0, 'trend': 'stable'}
    
    def _store_previous_values(self, metrics: Dict):
        """Store current metric values for next delta calculation."""
        try:
            for metric_name, metric_data in metrics.items():
                setattr(self, f'_prev_{metric_name}', metric_data.get('value', 0))
        except Exception as e:
            self.logger.error(f"Previous values storage error: {e}")
    
    def _get_new_alerts(self) -> List[Dict]:
        """Get new alerts since last check."""
        try:
            # In a real implementation, this would check for new alerts
            # For demo, occasionally return a new alert
            if np.random.random() < 0.1:  # 10% chance
                alert_types = [
                    ('Temperature Spike', 'warning'),
                    ('Pressure Anomaly', 'critical'),
                    ('Vibration High', 'warning'),
                    ('Device Offline', 'critical')
                ]
                
                alert_type, severity = np.random.choice(alert_types)
                device_id = f'DEVICE_{np.random.randint(1, 21):03d}'
                
                return [{
                    'id': f'alert_{int(datetime.now().timestamp())}',
                    'title': alert_type,
                    'message': f'{alert_type} detected on {device_id}',
                    'severity': severity,
                    'device_id': device_id,
                    'timestamp': datetime.now().isoformat()
                }]
            
            return []
            
        except Exception as e:
            self.logger.error(f"New alerts retrieval error: {e}")
            return []
    
    def _get_device_updates(self, df: pd.DataFrame) -> List[Dict]:
        """Get updated device information."""
        try:
            updates = []
            
            if not df.empty:
                # Get latest data for each device
                latest_df = df.groupby('device_id').last().reset_index()
                
                # Return updates for first 5 devices (limit for performance)
                for _, device in latest_df.head(5).iterrows():
                    updates.append({
                        'device_id': device['device_id'],
                        'value': round(device.get('value', 0), 2),
                        'health_score': round(device.get('health_score', 0.8) * 100, 1),
                        'status': device.get('status', 'normal'),
                        'timestamp': device.get('timestamp', datetime.now().isoformat())
                    })
            
            return updates
            
        except Exception as e:
            self.logger.error(f"Device updates error: {e}")
            return []
    
    def _get_status_changes(self, df: pd.DataFrame) -> List[Dict]:
        """Get recent device status changes."""
        try:
            # In a real implementation, this would track status changes
            # For demo, occasionally simulate a status change
            if np.random.random() < 0.05:  # 5% chance
                device_id = f'DEVICE_{np.random.randint(1, 21):03d}'
                old_status = np.random.choice(['normal', 'warning'])
                new_status = 'warning' if old_status == 'normal' else 'normal'
                
                return [{
                    'device_id': device_id,
                    'old_status': old_status,
                    'new_status': new_status,
                    'timestamp': datetime.now().isoformat()
                }]
            
            return []
            
        except Exception as e:
            self.logger.error(f"Status changes error: {e}")
            return []
    
    def get_device_summary(self, device_id: str) -> Dict:
        """
        Get comprehensive summary for a specific device.
        
        Args:
            device_id: Device identifier
            
        Returns:
            Device summary data
        """
        try:
            device_data = self._fetch_device_data()
            device = next((d for d in device_data if d.get('device_id') == device_id), None)
            
            if not device:
                return {'error': f'Device {device_id} not found'}
            
            # Get historical data for trends
            historical_data = self._get_device_historical_data(device_id, hours=24)
            
            summary = {
                'device_id': device_id,
                'device_name': device.get('device_name', ''),
                'device_type': device.get('device_type', ''),
                'location': device.get('location', ''),
                'status': device.get('status', 'unknown'),
                'current_metrics': {
                    'value': device.get('value', 0),
                    'unit': device.get('unit', ''),
                    'health_score': round(device.get('health_score', 0) * 100, 1),
                    'efficiency_score': round(device.get('efficiency_score', 0) * 100, 1),
                    'operating_hours': device.get('operating_hours', 0),
                    'days_since_maintenance': device.get('days_since_maintenance', 0)
                },
                'trends': self._calculate_device_trends(historical_data),
                'alerts': self._get_device_alerts(device_id),
                'recommendations': self._get_device_recommendations(device),
                'last_updated': device.get('timestamp', datetime.now().isoformat())
            }
            
            return summary
            
        except Exception as e:
            self.logger.error(f"Device summary error for {device_id}: {e}")
            return {'error': str(e)}
    
    def _get_device_historical_data(self, device_id: str, hours: int = 24) -> List[Dict]:
        """Get historical data for a specific device."""
        try:
            db_path = "DATABASE/health_data.db"
            
            if not Path(db_path).exists():
                # Generate sample historical data
                return self._generate_sample_historical_data(device_id, hours)
            
            with sqlite3.connect(db_path) as conn:
                query = """
                    SELECT * FROM device_data 
                    WHERE device_id = ? AND timestamp >= datetime('now', '-{} hours')
                    ORDER BY timestamp ASC
                """.format(hours)
                
                df = pd.read_sql_query(query, conn, params=[device_id])
                return df.to_dict('records')
                
        except Exception as e:
            self.logger.error(f"Historical data retrieval error for {device_id}: {e}")
            return []
    
    def _generate_sample_historical_data(self, device_id: str, hours: int) -> List[Dict]:
        """Generate sample historical data for demonstration."""
        try:
            data = []
            now = datetime.now()
            
            for i in range(hours):
                timestamp = now - timedelta(hours=hours-1-i)
                
                # Generate realistic pattern
                base_value = 25 + 5 * np.sin(i * 0.1)  # Daily temperature pattern
                noise = np.random.normal(0, 1)
                
                data.append({
                    'device_id': device_id,
                    'timestamp': timestamp.isoformat(),
                    'value': round(base_value + noise, 2),
                    'health_score': np.random.uniform(0.7, 0.95),
                    'efficiency_score': np.random.uniform(0.75, 0.92),
                    'status': np.random.choice(['normal', 'warning'], p=[0.9, 0.1])
                })
            
            return data
            
        except Exception as e:
            self.logger.error(f"Sample historical data generation error: {e}")
            return []
    
    def _calculate_device_trends(self, historical_data: List[Dict]) -> Dict:
        """Calculate trends for device metrics."""
        try:
            if not historical_data:
                return {'health': 'stable', 'efficiency': 'stable', 'value': 'stable'}
            
            df = pd.DataFrame(historical_data)
            trends = {}
            
            for metric in ['health_score', 'efficiency_score', 'value']:
                if metric in df.columns:
                    values = df[metric].dropna()
                    if len(values) >= 3:
                        # Simple linear trend
                        x = np.arange(len(values))
                        slope, _, _, _, _ = stats.linregress(x, values)
                        
                        if slope > 0.001:
                            trend = 'improving'
                        elif slope < -0.001:
                            trend = 'declining'
                        else:
                            trend = 'stable'
                    else:
                        trend = 'stable'
                    
                    trends[metric.replace('_score', '')] = trend
            
            return trends
            
        except Exception as e:
            self.logger.error(f"Device trends calculation error: {e}")
            return {'health': 'stable', 'efficiency': 'stable', 'value': 'stable'}
    
    def _get_device_alerts(self, device_id: str) -> List[Dict]:
        """Get alerts for a specific device."""
        try:
            # In a real implementation, this would query the alert system
            # For demo, return sample alerts
            alerts = []
            
            if np.random.random() < 0.3:  # 30% chance of having alerts
                alert_types = [
                    ('Maintenance Due', 'warning'),
                    ('Performance Degraded', 'info'),
                    ('Sensor Calibration', 'warning')
                ]
                
                for alert_type, severity in alert_types[:np.random.randint(1, 3)]:
                    alerts.append({
                        'title': alert_type,
                        'severity': severity,
                        'timestamp': (datetime.now() - timedelta(hours=np.random.randint(1, 48))).isoformat()
                    })
            
            return alerts
            
        except Exception as e:
            self.logger.error(f"Device alerts error for {device_id}: {e}")
            return []
    
    def _get_device_recommendations(self, device: Dict) -> List[Dict]:
        """Get recommendations for a specific device."""
        try:
            recommendations = []
            
            health_score = device.get('health_score', 1.0)
            efficiency_score = device.get('efficiency_score', 1.0)
            days_since_maintenance = device.get('days_since_maintenance', 0)
            
            # Health-based recommendations
            if health_score < 0.6:
                recommendations.append({
                    'type': 'maintenance',
                    'priority': 'high',
                    'title': 'Device Health Critical',
                    'description': f'Health score is {health_score*100:.1f}% - immediate attention required',
                    'action': 'Schedule immediate inspection and maintenance'
                })
            elif health_score < 0.8:
                recommendations.append({
                    'type': 'maintenance',
                    'priority': 'medium',
                    'title': 'Health Score Below Normal',
                    'description': f'Health score is {health_score*100:.1f}% - consider maintenance',
                    'action': 'Schedule maintenance within next week'
                })
            
            # Efficiency-based recommendations
            if efficiency_score < 0.7:
                recommendations.append({
                    'type': 'optimization',
                    'priority': 'medium',
                    'title': 'Low Efficiency Detected',
                    'description': f'Efficiency is {efficiency_score*100:.1f}% - optimization needed',
                    'action': 'Review operational parameters and optimize settings'
                })
            
            # Maintenance schedule recommendations
            if days_since_maintenance > 90:
                recommendations.append({
                    'type': 'maintenance',
                    'priority': 'high',
                    'title': 'Maintenance Overdue',
                    'description': f'Last maintenance was {days_since_maintenance} days ago',
                    'action': 'Schedule maintenance immediately'
                })
            elif days_since_maintenance > 60:
                recommendations.append({
                    'type': 'maintenance',
                    'priority': 'low',
                    'title': 'Maintenance Due Soon',
                    'description': f'Last maintenance was {days_since_maintenance} days ago',
                    'action': 'Plan maintenance within next 2 weeks'
                })
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"Device recommendations error: {e}")
            return []
    
    def export_dashboard_data(self, format_type: str = 'json', include_historical: bool = False) -> Dict:
        """
        Export dashboard data in specified format.
        
        Args:
            format_type: Export format ('json', 'csv', 'excel')
            include_historical: Whether to include historical data
            
        Returns:
            Export data or file path
        """
        try:
            self.logger.info(f"Exporting dashboard data in {format_type} format")
            
            # Get comprehensive data
            overview = self.get_dashboard_overview()
            device_data = self._fetch_device_data()
            
            export_data = {
                'export_timestamp': datetime.now().isoformat(),
                'overview': overview,
                'devices': device_data
            }
            
            if include_historical:
                export_data['historical_data'] = self._get_all_historical_data()
            
            if format_type == 'json':
                # Save as JSON file
                export_path = self.cache_path / f"dashboard_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(export_path, 'w') as f:
                    json.dump(export_data, f, indent=2, default=str)
                
                return {'export_path': str(export_path), 'format': 'json'}
            
            elif format_type == 'csv':
                # Convert to CSV format
                df = pd.DataFrame(device_data)
                export_path = self.cache_path / f"dashboard_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                df.to_csv(export_path, index=False)
                
                return {'export_path': str(export_path), 'format': 'csv'}
            
            else:
                return {'error': f'Unsupported export format: {format_type}'}
                
        except Exception as e:
            self.logger.error(f"Dashboard data export error: {e}")
            return {'error': str(e)}
    
    def _get_all_historical_data(self, days: int = 7) -> List[Dict]:
        """Get historical data for all devices."""
        try:
            db_path = "DATABASE/health_data.db"
            
            if not Path(db_path).exists():
                return []
            
            with sqlite3.connect(db_path) as conn:
                query = """
                    SELECT * FROM device_data 
                    WHERE timestamp >= datetime('now', '-{} days')
                    ORDER BY timestamp DESC
                """.format(days)
                
                df = pd.read_sql_query(query, conn)
                return df.to_dict('records')
                
        except Exception as e:
            self.logger.error(f"Historical data retrieval error: {e}")
            return []
    
    def clear_cache(self):
        """Clear all cached data."""
        try:
            self.data_cache.clear()
            self.cache_timestamps.clear()
            self.realtime_buffer.clear()
            
            # Clear cache files
            cache_files = list(self.cache_path.glob("*.cache"))
            for cache_file in cache_files:
                cache_file.unlink()
            
            self.logger.info("Dashboard cache cleared")
            
        except Exception as e:
            self.logger.error(f"Cache clear error: {e}")
    
    def get_cache_statistics(self) -> Dict:
        """Get cache usage statistics."""
        try:
            total_cache_entries = len(self.data_cache)
            cache_size = sum(len(str(v)) for v in self.data_cache.values())
            
            return {
                'total_entries': total_cache_entries,
                'estimated_size_bytes': cache_size,
                'realtime_buffer_size': sum(len(buffer) for buffer in self.realtime_buffer.values()),
                'last_updated': max(self.cache_timestamps.values()) if self.cache_timestamps else None,
                'cache_hit_ratio': 0.85  # Placeholder - would track actual hits/misses in real implementation
            }
            
        except Exception as e:
            self.logger.error(f"Cache statistics error: {e}")
            return {}


# Example usage and testing
if __name__ == "__main__":
    # Initialize dashboard helper
    dashboard = DashboardHelper()
    
    print("=== DIGITAL TWIN DASHBOARD HELPER DEMO ===\n")
    
    # 1. Get dashboard overview
    print("1. Getting dashboard overview...")
    overview = dashboard.get_dashboard_overview()
    
    print(f"System Metrics:")
    system_metrics = overview.get('system_metrics', {})
    print(f"  - Total Devices: {system_metrics.get('total_devices', 0)}")
    print(f"  - Active Devices: {system_metrics.get('active_devices', 0)}")
    print(f"  - System Uptime: {system_metrics.get('uptime', 0)}%")
    print(f"  - Response Time: {system_metrics.get('response_time_ms', 0)} ms")
    
    print(f"\nHealth Metrics:")
    health_metrics = overview.get('health_metrics', {})
    print(f"  - Average Health: {health_metrics.get('average_health', 0)}%")
    print(f"  - Health Trend: {health_metrics.get('health_trend', 'stable')}")
    print(f"  - Devices Needing Attention: {health_metrics.get('devices_needing_attention', 0)}")
    
    print(f"\nPerformance Metrics:")
    performance_metrics = overview.get('performance_metrics', {})
    print(f"  - Average Efficiency: {performance_metrics.get('average_efficiency', 0)}%")
    print(f"  - Efficiency Trend: {performance_metrics.get('efficiency_trend', 'stable')}")
    print(f"  - Devices Due Maintenance: {performance_metrics.get('devices_due_maintenance', 0)}")
    
    print(f"\nEnergy Metrics:")
    energy_metrics = overview.get('energy_metrics', {})
    print(f"  - Current Power: {energy_metrics.get('current_power_kw', 0)} kW")
    print(f"  - Daily Energy: {energy_metrics.get('daily_energy_kwh', 0)} kWh")
    print(f"  - Monthly Cost: ${energy_metrics.get('monthly_cost_usd', 0)}")
    
    print(f"\nStatus Distribution:")
    status_distribution = overview.get('status_distribution', {})
    for status, count in status_distribution.items():
        print(f"  - {status.title()}: {count} devices")
    
    print(f"\nAlerts Summary:")
    alerts_summary = overview.get('alerts_summary', {})
    print(f"  - Total Alerts: {alerts_summary.get('total_alerts', 0)}")
    print(f"  - Critical Alerts: {alerts_summary.get('critical_alerts', 0)}")
    print(f"  - Warning Alerts: {alerts_summary.get('warning_alerts', 0)}")
    
    # 2. Test chart data preparation
    print("\n" + "="*50)
    print("2. Testing chart data preparation...")
    
    # Line chart data
    line_chart = dashboard.prepare_chart_data('line', time_range='24h')
    if 'error' not in line_chart:
        print(f" Line Chart: {len(line_chart.get('datasets', []))} datasets with {len(line_chart.get('labels', []))} data points")
    else:
        print(f" Line Chart Error: {line_chart['error']}")
    
    # Bar chart data
    bar_chart = dashboard.prepare_chart_data('bar')
    if 'error' not in bar_chart:
        print(f" Bar Chart: {len(bar_chart.get('labels', []))} categories")
    else:
        print(f" Bar Chart Error: {bar_chart['error']}")
    
    # Pie chart data
    pie_chart = dashboard.prepare_chart_data('pie')
    if 'error' not in pie_chart:
        print(f" Pie Chart: {len(pie_chart.get('labels', []))} segments")
    else:
        print(f" Pie Chart Error: {pie_chart['error']}")
    
    # Gauge chart data
    gauge_chart = dashboard.prepare_chart_data('gauge')
    if 'error' not in gauge_chart:
        print(f" Gauge Chart: Value = {gauge_chart.get('value', 0)}%")
    else:
        print(f" Gauge Chart Error: {gauge_chart['error']}")
    
    # Heatmap data
    heatmap = dashboard.prepare_chart_data('heatmap')
    if 'error' not in heatmap:
        print(f" Heatmap: {len(heatmap.get('yLabels', []))} x {len(heatmap.get('xLabels', []))} matrix")
    else:
        print(f" Heatmap Error: {heatmap['error']}")
    
    # 3. Test real-time updates
    print("\n" + "="*50)
    print("3. Testing real-time updates...")
    
    realtime_data = dashboard.get_realtime_updates()
    if 'error' not in realtime_data:
        metrics = realtime_data.get('metrics', {})
        print("Real-time Metrics:")
        for metric_name, metric_data in metrics.items():
            value = metric_data.get('value', 0)
            delta = metric_data.get('delta', 0)
            trend = metric_data.get('trend', 'stable')
            print(f"  - {metric_name.replace('_', ' ').title()}: {value} ({delta:+.1f}, {trend})")
        
        new_alerts = realtime_data.get('alerts', [])
        print(f"\nNew Alerts: {len(new_alerts)}")
        for alert in new_alerts[:3]:  # Show first 3 alerts
            print(f"  - [{alert.get('severity', 'info').upper()}] {alert.get('title', '')}: {alert.get('message', '')}")
    else:
        print(f" Real-time Updates Error: {realtime_data['error']}")
    
    # 4. Test device summary
    print("\n" + "="*50)
    print("4. Testing device summary...")
    
    device_summary = dashboard.get_device_summary('DEVICE_001')
    if 'error' not in device_summary:
        print(f"Device: {device_summary.get('device_name', 'Unknown')}")
        print(f"Type: {device_summary.get('device_type', 'Unknown')}")
        print(f"Location: {device_summary.get('location', 'Unknown')}")
        print(f"Status: {device_summary.get('status', 'Unknown')}")
        
        current_metrics = device_summary.get('current_metrics', {})
        print(f"Current Value: {current_metrics.get('value', 0)} {current_metrics.get('unit', '')}")
        print(f"Health Score: {current_metrics.get('health_score', 0)}%")
        print(f"Efficiency: {current_metrics.get('efficiency_score', 0)}%")
        
        trends = device_summary.get('trends', {})
        print(f"Trends: Health={trends.get('health', 'stable')}, "
              f"Efficiency={trends.get('efficiency', 'stable')}, "
              f"Value={trends.get('value', 'stable')}")
        
        recommendations = device_summary.get('recommendations', [])
        print(f"Recommendations: {len(recommendations)}")
        for rec in recommendations[:2]:  # Show first 2 recommendations
            print(f"  - [{rec.get('priority', 'low').upper()}] {rec.get('title', '')}")
    else:
        print(f" Device Summary Error: {device_summary['error']}")
    
    # 5. Test data export
    print("\n" + "="*50)
    print("5. Testing data export...")
    
    # JSON export
    json_export = dashboard.export_dashboard_data('json', include_historical=False)
    if 'error' not in json_export:
        print(f" JSON Export: {json_export.get('export_path', 'Unknown path')}")
    else:
        print(f" JSON Export Error: {json_export['error']}")
    
    # CSV export
    csv_export = dashboard.export_dashboard_data('csv', include_historical=False)
    if 'error' not in csv_export:
        print(f" CSV Export: {csv_export.get('export_path', 'Unknown path')}")
    else:
        print(f" CSV Export Error: {csv_export['error']}")
    
    # 6. Test cache statistics
    print("\n" + "="*50)
    print("6. Cache statistics...")
    
    cache_stats = dashboard.get_cache_statistics()
    print(f"Cache Entries: {cache_stats.get('total_entries', 0)}")
    print(f"Estimated Size: {cache_stats.get('estimated_size_bytes', 0):,} bytes")
    print(f"Buffer Size: {cache_stats.get('realtime_buffer_size', 0)}")
    print(f"Hit Ratio: {cache_stats.get('cache_hit_ratio', 0)*100:.1f}%")
    
    # 7. Performance test
    print("\n" + "="*50)
    print("7. Performance test...")
    
    import time
    
    # Time dashboard overview generation
    start_time = time.time()
    for i in range(5):
        overview = dashboard.get_dashboard_overview()
    overview_time = (time.time() - start_time) / 5
    print(f"Average Overview Generation Time: {overview_time*1000:.1f} ms")
    
    # Time chart data preparation
    start_time = time.time()
    for chart_type in ['line', 'bar', 'pie', 'gauge']:
        dashboard.prepare_chart_data(chart_type)
    chart_time = (time.time() - start_time) / 4
    print(f"Average Chart Preparation Time: {chart_time*1000:.1f} ms")
    
    # Time real-time updates
    start_time = time.time()
    for i in range(10):
        dashboard.get_realtime_updates()
    realtime_time = (time.time() - start_time) / 10
    print(f"Average Real-time Update Time: {realtime_time*1000:.1f} ms")
    
    # 8. Memory usage estimation
    print("\n" + "="*50)
    print("8. Memory usage estimation...")
    
    import sys
    
    # Estimate object sizes
    overview_size = sys.getsizeof(str(overview))
    chart_size = sys.getsizeof(str(line_chart))
    realtime_size = sys.getsizeof(str(realtime_data))
    
    print(f"Overview Data Size: {overview_size:,} bytes")
    print(f"Chart Data Size: {chart_size:,} bytes")
    print(f"Real-time Data Size: {realtime_size:,} bytes")
    print(f"Total Estimated Usage: {(overview_size + chart_size + realtime_size):,} bytes")
    
    # 9. Configuration display
    print("\n" + "="*50)
    print("9. Current configuration...")
    
    print("Aggregation Config:")
    for device_type, config in dashboard.aggregation_config.items():
        print(f"  {device_type}: {config['normal_range']} {config['unit']} "
              f"(precision: {config['precision']})")
    
    print("\nColor Schemes:")
    print(f"  Primary Colors: {len(dashboard.color_schemes['primary'])} colors")
    print(f"  Status Colors: {list(dashboard.color_schemes['status'].keys())}")
    print(f"  Health Colors: {list(dashboard.color_schemes['health'].keys())}")
    
    print(f"\nCache Settings:")
    print(f"  Cache Path: {dashboard.cache_path}")
    print(f"  Cache TTL: {dashboard.cache_ttl} seconds")
    print(f"  Buffer Max Length: {dashboard.realtime_buffer.default_factory().maxlen}")
    
    # 10. Cleanup and summary
    print("\n" + "="*50)
    print("10. Demo summary and cleanup...")
    
    # Show final statistics
    final_cache_stats = dashboard.get_cache_statistics()
    print(f"Final cache entries: {final_cache_stats.get('total_entries', 0)}")
    
    # Clear cache
    dashboard.clear_cache()
    print(" Cache cleared")
    
    # Verify cleanup
    cleaned_cache_stats = dashboard.get_cache_statistics()
    print(f"Cache entries after cleanup: {cleaned_cache_stats.get('total_entries', 0)}")
    
    print("\n=== DEMO COMPLETED SUCCESSFULLY ===")
    print("\nDashboard Helper Features Tested:")
    print(" Dashboard overview generation")
    print(" Chart data preparation (5 types)")
    print(" Real-time updates")
    print(" Device summaries")
    print(" Data export (JSON/CSV)")
    print(" Cache management")
    print(" Performance metrics")
    print(" Memory usage tracking")
    print(" Configuration display")
    
    print(f"\nTotal execution time: {time.time() - start_time:.2f} seconds")
    print("Dashboard Helper is ready for production use!")